{"cells":[{"cell_type":"markdown","source":["# TensorFlow NLP Zero to Hero Tutorial"],"metadata":{}},{"cell_type":"markdown","source":["## **Part 1:** Tokenisation"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.text import Tokenizer"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["sentences = [\n","    'I love my dog',\n","    'I love my cat'\n","]"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["tokenizer = Tokenizer(num_words=100)\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","print(word_index)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n"]}],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["sentences = [\n","    'i love my dog',\n","    'I, love my cat',\n","    'You love my dog!'\n","]\n","tokenizer = Tokenizer(num_words=100)\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","print(word_index)\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n"]}],"metadata":{}},{"cell_type":"markdown","source":["## **Part 2:** Sequences"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["sentences = [\n","    'i love my dog',\n","    'I, love my cat',\n","    'You love my dog!',\n","    'Do you think my dog is amazing?'\n","]\n","tokenizer = Tokenizer(num_words=100)\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","sequences=tokenizer.texts_to_sequences(sentences) ##generate sequences\n","print(word_index)\n","print(sequences)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'my': 1, 'love': 2, 'dog': 3, 'i': 4, 'you': 5, 'cat': 6, 'do': 7, 'think': 8, 'is': 9, 'amazing': 10}\n","[[4, 2, 1, 3], [4, 2, 1, 6], [5, 2, 1, 3], [7, 5, 8, 1, 3, 9, 10]]\n"]}],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["test_data=[\n","    'i really love my dog',\n","    'my dog loves my manatee'\n","]\n","test_seq=tokenizer.texts_to_sequences(test_data) #tokenizer object from ^ previous cell\n","print(test_seq) # missing 'really', 'loves' and 'manatee'"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[4, 2, 1, 3], [1, 3, 1]]\n"]}],"metadata":{}},{"cell_type":"markdown","source":["### OOV Tokens"],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["sentences = [\n","    'i love my dog',\n","    'I, love my cat',\n","    'You love my dog!',\n","    'Do you think my dog is amazing?'\n","]\n","tokenizer = Tokenizer(num_words=100,oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","sequences=tokenizer.texts_to_sequences(sentences) ##generate sequences\n","print(word_index)\n","print(sequences)"],"outputs":[{"output_type":"stream","name":"stdout","text":["{'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n","[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n"]}],"metadata":{}},{"cell_type":"code","execution_count":26,"source":["test_data=[\n","    'i really love my dog haha',\n","    'my dog loves my manatee'\n","]\n","test_seq=tokenizer.texts_to_sequences(test_data) #tokenizer object from ^ previous cell\n","display(test_seq) # missing 'really', 'loves' and 'manatee'\n","\n"],"outputs":[{"output_type":"display_data","data":{"text/plain":["[[5, 1, 3, 2, 4, 1], [2, 4, 1, 2, 1]]"]},"metadata":{}}],"metadata":{}},{"cell_type":"markdown","source":["### Padding"],"metadata":{}},{"cell_type":"code","execution_count":20,"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from IPython.display import display"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":22,"source":["sentences = [\n","    'i love my dog',\n","    'I, love my cat',\n","    'You love my dog!',\n","    'Do you think my dog is amazing?'\n","]\n","tokenizer = Tokenizer(num_words=100,oov_token=\"<OOV>\")\n","tokenizer.fit_on_texts(sentences)\n","word_index = tokenizer.word_index\n","sequences=tokenizer.texts_to_sequences(sentences) ##generate sequences\n","display(word_index)\n","display(sequences)\n","\n","padded=pad_sequences(sequences)\n","display(padded)\n"],"outputs":[{"output_type":"display_data","data":{"text/plain":["{'<OOV>': 1,\n"," 'my': 2,\n"," 'love': 3,\n"," 'dog': 4,\n"," 'i': 5,\n"," 'you': 6,\n"," 'cat': 7,\n"," 'do': 8,\n"," 'think': 9,\n"," 'is': 10,\n"," 'amazing': 11}"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["[[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["array([[ 0,  0,  0,  5,  3,  2,  4],\n","       [ 0,  0,  0,  5,  3,  2,  7],\n","       [ 0,  0,  0,  6,  3,  2,  4],\n","       [ 8,  6,  9,  2,  4, 10, 11]], dtype=int32)"]},"metadata":{}}],"metadata":{}},{"cell_type":"code","execution_count":27,"source":["padded=pad_sequences(sequences,padding='post') #shift padding to back of sentences\n","display(padded)"],"outputs":[{"output_type":"display_data","data":{"text/plain":["array([[ 5,  3,  2,  4,  0,  0,  0],\n","       [ 5,  3,  2,  7,  0,  0,  0],\n","       [ 6,  3,  2,  4,  0,  0,  0],\n","       [ 8,  6,  9,  2,  4, 10, 11]], dtype=int32)"]},"metadata":{}}],"metadata":{}},{"cell_type":"code","execution_count":29,"source":["padded=pad_sequences(sequences,padding='post',truncating='post',maxlen=5) #set length limit\n","display(padded)"],"outputs":[{"output_type":"display_data","data":{"text/plain":["array([[5, 3, 2, 4, 0],\n","       [5, 3, 2, 7, 0],\n","       [6, 3, 2, 4, 0],\n","       [8, 6, 9, 2, 4]], dtype=int32)"]},"metadata":{}}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit ('tf': conda)"},"interpreter":{"hash":"eee345bad24cded5c432354299344c73e925880824f06d3999cf18aaca5ae3fa"}}}